// Copyright 2013 Google Inc. All rights reserved.
// Copyright 2020 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Normalizes a program based on the results of reachability analysis.
def TRANSFERRABLE_FACTS = (Fact.M_ABSTRACT | Fact.M_INLINE | Fact.M_OPERATOR | Fact.M_NEW | Fact.M_EMPTY | Fact.M_EQUALS);
class ReachabilityNormalizer(ra: ReachabilityAnalyzer) {
	def liveClasses = Vector<RaClass>.new();
	def context = SsaContext.new(ra.compiler, ra.prog);
	def fields = Vector<IrField>.new();
	def typeMap = TypeUtil.newTypeMap<TypeNorm>();
	var recordMap = V3.newRecordMap<Record>(); // XXX: canonicalize equivalent variant records
	var complexRecordMap = V3.newRecordMap<Array<Val>>();
	var newIr = IrModule.new();
	var specializer: Specializer;
	var virtuals: List<RaVirtual>;
	var ovfAlloc: OverflowFieldAllocator;  // OVF where to allocate the fields?

	def normalize() {
		if (Aeneas.PRINT_DEAD_CODE.get()) DeadCodeAnalyzer.new(ra).report();
		// layout fields into classes
		ra.arrays.apply(visitArrayType);
		ra.classes.apply(visitClassType);
		if (ra.compiler.PartialSpecialization) {
			// if partial specialization is enabled, do specialization analysis
			(specializer = Specializer.new(ra, this)).specialize();
		}
		ra.classes.apply(layoutVtable);
		Lists.apply(virtuals, layoutMtable);
		ra.classes.apply(createIrClass);
		// create new roots for the new IrModule
		var old = ra.oldIr.roots;
		newIr.roots.grow(old.length);
		newIr.roots.length = old.length;
		for (i < old.length) {
			var o = old[i];
			newIr.roots[i] = IrRoot.new(o.name, normalizeMethodRef(o.spec));
		}
		ra.prog.ir = newIr;
		// do remaining work; normalize record instances
		ra.queue.drain();
		ra.liveMethods.apply(normCode);
		if (ovfAlloc != null) allocOverflowFieldRecord();
	}
	def visitClassType(rc: RaClass) {
		if (rc.minClassId < 0) {
			var ic = rc;
			while (ic.parent != null) ic = ic.parent; // start at root

			if (V3.isVariant(ic.oldType)) {
				if (ic.children == null) layoutDataType(ic);
				else layoutVariant(ic);
			} else {
				layoutClass(ic);
			}
		}
		var tn = norm(rc.oldType);
		if (V3.isComponent(rc.oldType)) {
			var comp = V3.componentDecl(rc.oldType), newRecord: Record;
			if (rc.instances != null) {
				// normalize component record
				var oldRecord = rc.instances.head;
				newRecord = ra.prog.newRecord(tn.newType, rc.normFields.length);
				complexRecordMap[oldRecord] = NO_VALUES;
				ra.queue.add(normClassRecord, (rc, oldRecord, newRecord.values));
			}
			ra.prog.setComponentRecord(comp, newRecord);
		} else if (rc.dataNorm != null) {
			// normalize data records
			for (l = rc.instances; l != null; l = l.tail) {
				var oldRecord = l.head, result = Array<Val>.new(rc.dataNorm.size);
				complexRecordMap[oldRecord] = result;
				ra.queue.add(normClassRecord, (rc, oldRecord, result));
			}
		} else {
			// create and map new records to be normalized
			for (l = rc.instances; l != null; l = l.tail) {
				var oldRecord = l.head, newRecord = ra.prog.newRecord(tn.newType, rc.normFields.length);
				recordMap[l.head] = newRecord;
				ra.queue.add(normClassRecord, (rc, oldRecord, newRecord.values));
			}
		}
		for (ml in rc.methods) {
			// Create IrMethods for all methods that didn't have norm signatures
			for (l = ml; l != null; l = l.tail) {
				var rm = l.head, m = rm.orig;
				if (rm.norm == null) {
					var ftype = FuncNorm.!(norm(if(rm.spec == null, m.sig.funcType(), rm.spec.getMethodType())));
					var ft = Function.CLOSURE.create(ftype.sub[0].nested); // correct the typecon; norm() returns FUNCREF type
					var typeParams = if(rm.spec != null, rm.spec.getTypes().methodTypeArgs);
					rm.norm = IrMethod.new(rc.oldType, typeParams, FuncType.!(ft).sig());
				}
				rm.norm.facts = m.facts & TRANSFERRABLE_FACTS;
				rm.norm.source = m.source;
			}
		}
	}
	def visitArrayType(rt: RaArray) {
		var tn = ArrayNorm.!(norm(rt.oldType));
		if (tn.oldType != tn.newType) {
			if (tn.enorm != null) {
				// normalize elements of mixed arrays
				for (l = rt.instances; l != null; l = l.tail) {
					var newRecord = ra.prog.newRecord(tn.newType, l.head.values.length);
					recordMap[l.head] = newRecord;
					ra.queue.add(normMixedArrayRecord, (tn, l.head, newRecord));
				}
			} else {
				// map complex arrays to arrays of records
				for (l = rt.instances; l != null; l = l.tail) {
					var newRecords = createComplexArrayRecord(l.head, tn);
					ra.queue.add(normComplexArrayRecord, (tn, l.head, newRecords));
				}
			}
		} else if (!rt.primitive) {
			// normalize simple arrays that are not primitive
			for (l = rt.instances; l != null; l = l.tail) {
				ra.queue.add(normSimpleArrayRecord, l.head);
			}
		}
	}
	def norm(t: Type) -> TypeNorm {
		if (t.open()) return V3.fail1("is open %q", t.render);
		var tn = typeMap[t];
		if (tn != null) return tn;
		// not in the hashmap, build appropriately
		match (t.typeCon.kind) {
			V3Kind.VOID => {
				tn = TypeNorm.new(t, Void.TYPE, TypeUtil.NO_TYPES);
			}
			V3Kind.COMPONENT => {
				tn = TypeNorm.new(t, Void.TYPE, TypeUtil.NO_TYPES);
			}
			V3Kind.ARRAY => {
				var at: ArrayNorm;
				var enorm = norm(V3Array.elementType(t));
				if (enorm.size == 0) {
					tn = at = ArrayNorm.new(t, V3.voidArrayType, null);
				} else if (enorm.sub == null) {
					tn = at = ArrayNorm.new(t, V3Array.newType(enorm.newType), null);
				} else if (ra.compiler.MixedArrays) {
					tn = at = ArrayNorm.new(t, V3Array.newType(enorm.newType), null);
					at.enorm = enorm;
				} else {
					var et = Arrays.map(enorm.sub, V3Array.newType);
					tn = at = ArrayNorm.new(t, Tuple.newType(Lists.fromArray(et)), et);
				}
			}
			V3Kind.CLOSURE => {
				// translate closure into (funcref, object) pair
				var pt = limit(norm(Function.getParamType(t)), ra.compiler.MaxParams-1);
				var rt = limit(norm(Function.getReturnType(t)), ra.compiler.MaxReturnValues);
				var ft = Function.FUNCREF.create(Lists.cons2(pt.0, rt.0));
				var ta = [ft, AnyObject.TYPE];
				tn = FuncNorm.new(t, Tuple.newType(Lists.fromArray(ta)), pt.1, rt.1, ta);
			}
			V3Kind.TUPLE => {
				// flatten tuples
				var vecT = Vector<Type>.new();
				var vecO = Vector<int>.new();
				var vecN = Vector<TypeNorm>.new();
				for (p = t.nested; p != null; p = p.tail) {
					var n = norm(p.head);
					vecO.put(vecT.length);
					vecN.put(n);
					n.addTo(vecT);
				}
				var ta = vecT.extract();
				tn = TupleNorm.new(t, Tuple.newType(Lists.fromArray(ta)), ta, vecN.extract(), vecO.extract());
			}
			V3Kind.VARIANT => {
				var rc = ra.getClass(t);
				if (rc != null && tryFlatteningDataType(rc)) tn = rc.dataNorm;
				else tn = TypeNorm.new(t, t, null);
			}
			_ => {
				tn = TypeNorm.new(t, t, null);
			}
		}
		typeMap[t] = tn;
		return tn;
	}
	def limit(tn: TypeNorm, len: int) -> (Type, Array<Type>) {
//		XXX.put3("limit %q %q |%d|\n", tn.oldType.render, tn.newType.render, len);
		if (tn.size <= len) return (tn.newType, TypeUtil.NO_TYPES);
		if (tn.sub == null) return (Void.TYPE, [tn.newType]);
		var t = Tuple.fromTypeArray(Arrays.range(tn.sub, 0, len));
		return (t, Arrays.range(tn.sub, len, tn.sub.length));
	}
	// number a class and lay out its fields, recursively visiting children
	def layoutClass(rc: RaClass) {
//		XXX.put1("layoutClass %q\n", rc.oldType.render);
		rc.minClassId = liveClasses.length;
		if (live(rc.raFacts) && !V3.isComponent(rc.oldType)) {
			liveClasses.put(rc);
		}
		layoutFields(rc);
		for (l = rc.children; l != null; l = l.tail) layoutClass(l.head);
		rc.maxClassId = liveClasses.length;
	}
	// number a variant and children consistent with tagging order
	def layoutVariant(rc: RaClass) {
//		Terminal.put1("layoutVariant %q\n", rc.oldType.render);
		rc.minClassId = liveClasses.length;
		layoutFields(rc);
		var isEnum = rc.normFields.length == 0;
		for (l = rc.children; l != null; l = l.tail) {
			var c = l.head;
			layoutFields(c);
			var index = rc.minClassId + V3.getVariantTag(c.oldType);
			c.minClassId = index;
			c.maxClassId = index + 1;
			liveClasses.grow(index + 1);
			if (liveClasses.length < c.maxClassId) liveClasses.length = index + 1;
			liveClasses[index] = c;
			if (c.normFields.length > 0) isEnum = false;
		}
		rc.maxClassId = liveClasses.length;
		if (isEnum) markEnum(rc);
	}
	// number and lay out a data type, which may be flattened later
	def layoutDataType(rc: RaClass) {
//		XXX.put1("layoutDataType %q\n", rc.oldType.render);
		rc.minClassId = liveClasses.length;
		liveClasses.put(rc);
		layoutFields(rc);
//		XXX.put2(" %d fields, recursive = %d\n", rc.normFields.length, rc.recursive);
		if (rc.normFields.length == 0) markEnum(rc);
		rc.maxClassId = liveClasses.length;

	}
	def tryFlatteningDataType(rc: RaClass) -> bool {
		if (rc.parent != null || rc.children != null) return false; // not a simple data type
		if (rc.normFields == null) layoutFields(rc); // TODO: dangerous?
		if (rc.normFields.length > ra.compiler.MaxFlatDataValues || rc.recursive > 1 || rc.raFacts.RC_CLOSURE) return false;
		var of = rc.orig.fields;
		var origRanges = Array<(int, int)>.new(of.length);
		var normRanges = Array<(int, int)>.new(of.length);
		var vecO = Vector<Type>.new();
		var vecT = Vector<Type>.new();
		// map fields of original IrClass to ranges in the original and normalized type
		for (i < of.length) {
			var origStart = vecO.length, normStart = vecT.length;
			if (i <= rc.fields.length) {
				var rf = rc.fields[i];
				if (rf != null) {
					rf.raFacts |= RaFact.RC_FLAT;
					if (rf.normIndex >= 0) {
						if (rf.typeNorm != null) {
							rf.typeNorm.addTo(vecT);
						} else if (rf.fieldType != null) {
							rf.typeNorm = norm(rf.fieldType);
							rf.typeNorm.addTo(vecT);
						} else {
							vecT.put(rf.orig.fieldType);
						}
					}
				}
			}
			norm(IrSpec.new(rc.oldType, TypeUtil.NO_TYPES, of[i]).getFieldType()).addTo(vecO); // XXX: creating IrSpec to substitute type
			origRanges[i] = (origStart, vecO.length);
			normRanges[i] = (normStart, vecT.length);
		}
		var ta = vecT.extract();
		rc.dataNorm = DataNorm.new(rc.oldType, Tuple.newType(Lists.fromArray(ta)), origRanges, normRanges, ta);
		rc.raFacts |= RaFact.RC_FLAT;
		return true;
	}
	def markEnum(rc: RaClass) {
		// this and all children classes will be represented as enums
		rc.raFacts |= RaFact.RC_ENUM;
		for (l = rc.children; l != null; l = l.tail) l.head.raFacts |= RaFact.RC_ENUM;
	}
	// map a complex array to an array of records
	def createComplexArrayRecord(r: Record, rt: ArrayNorm) -> Array<Record> {
		var sub = rt.sub;
		if (sub == null) {
			var result = ra.prog.newRecord(rt.newType, r.values.length);
			recordMap[r] = result;
			return [result];
		} else {
			var complex = Array<Record>.new(sub.length);
			for (i < complex.length) {
				complex[i] = ra.prog.newRecord(sub[i], r.values.length);
			}
			if (complex.length == 1) recordMap[r] = complex[0];
			else complexRecordMap[r] = Arrays.map(complex, Val.!<Record>);
			return complex;
		}
	}
	// layout fields for classes and components
	def layoutFields(rc: RaClass) {
		fields.length = 0;
		fields.grow(rc.fields.length);  // gather fields into vector
		for (rf in rc.fields) {
			if (rf == null) continue;
			if (rf.norm != null) {
				// inherited this field from superclass
				for (f in rf.norm) fields.put(IrField.!(f.member));
				continue;
			}
			if (rf.isConst()) continue;
			if (rf.typeNorm == null && rf.fieldType != null) rf.typeNorm = norm(rf.fieldType);
			if (!rf.raFacts.RF_READ) continue;
			// add normalized field(s)
			rf.normIndex = fields.length;
			addField(rc, rf);
		}
		if (ra.compiler.target != null) {
			var start = if(rc.parent != null, rc.parent.normFields.length);
			ra.compiler.target.computeFieldOffsets(ra.prog, fields, start);
		}
		rc.normFields = fields.extract();
	}
	def addField(rc: RaClass, rf: RaField) {
		if (rf.fieldType == null) {
			// add single monomorphic field to the vector
			fields.put(rf.orig);
			rf.norm = [IrSpec.new(rc.oldType, [rc.oldType], rf.orig)];
		} else {
			// add normalized field(s) to the vector
			var tn = rf.typeNorm;
			var norms = Array<IrSpec>.new(tn.size);
			var facts = if(tn.size > 1, Fact.F_NORM, Facts.NONE);
			if (!rf.raFacts.RF_WRITTEN) facts |= (Fact.F_VALUE | Fact.O_FOLDABLE);
			for (i < norms.length) {
				var ft = if(tn.sub == null, tn.newType, tn.sub[i]);
				var nf = IrField.new(rc.oldType, ft);
				nf.setFact(facts);
				nf.source = rf.orig.source;
				norms[i] = IrSpec.new(rc.oldType, [rc.oldType], nf);
				fields.put(nf);
			}
			rf.norm = norms;
		}
	}
	// normalize a live instance of a class
	def normClassRecord(rc: RaClass, oldRecord: Record, array: Array<Val>) {
		var rfs = rc.fields;
		for (i < rfs.length) {
			var rf = rfs[i];
			if (rf != null && rf.normIndex >= 0) {
				var v = oldRecord.values[i];
				if (rf.fieldType == null) array[rf.normIndex] = normSimpleVal(v);
				else normValIntoArray(v, rf.typeNorm, array, rf.normIndex);
			}
		}
	}
	// normalize the live instances of a simple (i.e. size-1 element) array type
	def normSimpleArrayRecord(record: Record) {
		def v = record.values;
		for (i < v.length) v[i] = normSimpleVal(v[i]);
	}
	// normalize the live instances of a mixed array type
	def normMixedArrayRecord(rt: ArrayNorm, oldRecord: Record, newRecord: Record) {
		def v = oldRecord.values;
		for (i < v.length) newRecord.values[i] = normAsTupleVal(v[i], rt.enorm);
	}
	// normalize the live instances of a complex (i.e. size-N element) array type
	def normComplexArrayRecord(rt: ArrayNorm, oldRecord: Record, newRecords: Array<Record>) {
		var etn = norm(V3Array.elementType(rt.oldType));
		var old = oldRecord.values;
		var temp = Array<Val>.new(newRecords.length);
		for (i < old.length) {
			for (j < temp.length) temp[j] = null; // XXX: must clear temp array first
			normValIntoArray(old[i], etn, temp, 0);
			for (j < newRecords.length) {
				newRecords[j].values[i] = temp[j];
			}
		}
	}
	// normalize a record value into 1 or more records into the given array
	def normRecordIntoArray(r: Record, array: Array<Val>, index: int) {
		var simple = recordMap[r];
		if (simple != null) { // simple mapping
			array[index] = simple;
			return;
		}
		var complex = complexRecordMap[r];
		if (complex != null) { // complex mapping
			for (i < complex.length) {
				array[index + i] = complex[i];
			}
			return;
		}
		array[index] = r;
	}
	// map a record 1-1
	def normSimpleVal(v: Val) -> Val {
		if (Record.?(v)) {
			// assume that a record without an entry is mapped to itself
			var r = recordMap[Record.!(v)];
			return if(r == null, v, r);
		}
		return v; // assume all other values can be reused
	}
	def normAsTupleVal(v: Val, tn: TypeNorm) -> Val {
		if (v == null) return v;
		var values = Array<Val>.new(tn.size);
		normValIntoArray(v, tn, values, 0);
		if (tn.size == 1) return values[0];
		return TupleVal.new(values);
	}
	def layoutVtable(rc: RaClass) {
		var vtable = Vector<IrMethod>.new();
		if (rc.parent != null) vtable.puta(rc.parent.normMethods); // add superclass methods
		else vtable.put(null); // reserve a space for constructor
		// process all methods
		for (ml in rc.methods) {
			for (l = ml; l != null; l = l.tail) addMethod(vtable, rc, l.head);
		}
		rc.normMethods = vtable.extract();
	}
	def addMethod(vtable: Vector<IrMethod>, rc: RaClass, rm: RaMethod) {
		var m = rm.orig;
		if (!rm.raFacts.RM_LIVE) {
			// mark methods that are abstract
			rm.norm.ssa = null;
			rm.norm.facts |= Fact.M_ABSTRACT;
			if (!rm.isVirtual()) return; // not live, not virtual
		}
		if (m.facts.M_NEW) {
			// constructors always end up at slot 0
			rm.norm.facts |= Fact.M_NEW;
			vtable[0] = rm.norm;
			rm.norm.index = rm.normIndex = 0;
			return;
		}
		var sm = resolveMethodImpl(rc.parent, rm);
		if (sm == null) { // add a new method to the vtable
			rm.norm.index = rm.normIndex = vtable.length;
			vtable.put(rm.norm);
		} else if (sm != rm) { // overwrite existing vtable entry
			vtable[sm.normIndex] = rm.norm;
			rm.norm.index = rm.normIndex = sm.normIndex;
			rm.norm.facts |= Fact.M_OVERRIDE;
			sm.norm.facts |= Fact.M_OVERRIDDEN;
		}
		if (rm.virtual != null) virtuals = List.new(rm.virtual, virtuals);
	}
	def layoutMtable(rv: RaVirtual) {
		if (rv.mtable != null) return;
		var rm = rv.raMethod, rc = ra.makeClass(rm.receiver);
		var size = rc.maxClassId - rc.minClassId;
		if (ra.compiler.RaDevirtualize && size < 2) return; // no need for an mtable
		var table = Array<IrMethod>.new(size);
		rv.mtable = IrMtable.new(rm.norm, rc.minClassId, table);
		for (l = rc.subtypes; l != null; l = l.tail) { // fill out mtable
			var impl = resolveMethodImpl(l.head, rm);
			if (rv.mtable.table.length > 0) {
				rv.mtable.table[l.head.minClassId - rv.mtable.rootId] = impl.norm;
			}
		}
		setMtable(rc, rv); // set mtable for all child virtual methods
	}
	def setMtable(rc: RaClass, rv: RaVirtual) {
		var rm = rc.findRaMethod(rv.raMethod);
		if (rm != null && rm.virtual != null) rm.virtual.mtable = rv.mtable;
		for (l = rc.children; l != null; l = l.tail) {
			setMtable(l.head, rv);
		}
	}
	def resolveMethodImpl(rc: RaClass, rm: RaMethod) -> RaMethod {
		var m = rm.orig, sm: RaMethod;
		for (sc = rc; sc != null; sc = sc.parent) {
			// find super method, if any
			if (m.index >= sc.methods.length) break;
			sm = sc.findRaMethod(rm);
			if (sm != null) break;
		}
		return sm;
	}
	def normValIntoArray(v: Val, tn: TypeNorm, array: Array<Val>, index: int) {
		match (v) {
			null => ;
			x: Record => {
				normRecordIntoArray(x, array, index);
			}
			x: Closure => {
				// closure: normalize record and method
				// normalize closure value as (funcval, object) pair
				array[index] = FuncVal.new(normalizeMethodRef(x.memberRef));
				if (x.val != null) {
					var r = Record.!(x.val); // XXX: assumes closure value is a record
					if (!V3.isComponent(r.rtype)) array[index + 1] = normSimpleVal(r);
				}
			}
			x: TupleVal => {
				// tuple: recursively normalize all of the sub
				var tnn = TupleNorm.!(tn).nested;
				for (i < tnn.length) {
					normValIntoArray(x.values[i], tnn[i], array, index);
					index = index + tnn[i].size;
				}
			}
			_ => if (index < array.length) array[index] = v;
		}
	}
	def normalizeMethodRef(spec: IrSpec) -> IrSpec {
		var rm = spec.asMethod().raMethod;
		var ta = spec.typeArgs;
		if (rm == null) {
			var rc = ra.makeClass(spec.receiver);
			rm = rc.findMethod(spec.member.index, ta);
			if (rm == null) return V3.fail1("ReachabilityError: method %q not found", spec.render);
		}
		return IrSpec.new(ta[0], ta, rm.norm);
	}
	def createIrClass(rc: RaClass) {
		var sc = if(rc.parent != null, rc.parent.normClass);
		var ic = IrClass.new(rc.oldType, null, sc, rc.normFields, rc.normMethods);
		ic.minClassId = rc.minClassId;
		ic.maxClassId = rc.maxClassId;
		rc.normClass = ic;
		if (rc.raFacts.RC_LIVE) ic.facts |= Fact.C_HEAP;
		if (rc.raFacts.RC_ALLOC) ic.facts |= Fact.C_ALLOCATED;
		if (rc.raFacts.RC_ENUM) ic.facts |= Fact.C_ENUM;
		newIr.setIrClass(rc.oldType, ic);
		var i = 0;
		for (f in ic.fields) {
			if (f != null) f.index = i;
			i++;
		}
	}
	def normCode(rm: RaMethod) {
		context.spec = rm.spec;
		context.enterMethod(rm.orig);
		if (specializer != null && rm.spec != null) {
			// use specializer to generate appropriate code for method
			if (specializer.normCode(context, rm)) return;
		}
		SsaRaNormalizer.new(context, this).build(rm.norm);
		newIr.methods.put(rm.norm);
	}
	def allocOverflowFields(ftype: FuncNorm) {
		if (ftype.ovfParamFields != null) return;
		if (ovfAlloc == null) {
			var prog = context.prog;
			var name = Arrays.concat(prog.name(), "$ovf");
			var decl = VstComponent.new(false, Token.new("<generated>", name, 0, 0), null);
			var typeCon = V3Component_TypeCon.new(decl, prog.typeCache);
			decl.memberMap = Strings.newMap();
			var receiver = typeCon.create0();
			decl.recordIndex = prog.vst.numComponents++;
			ovfAlloc = OverflowFieldAllocator.new(decl, receiver, context.compiler.AnyRefOverflow);
		}
		ovfAlloc.group++;
		ftype.ovfParamFields = Arrays.map(ftype.ovfParamTypes, ovfAlloc.next);
		ftype.ovfReturnFields = Arrays.map(ftype.ovfReturnTypes, ovfAlloc.next);
	}
	def allocOverflowFieldRecord() {
		var r = context.prog.newRecord(ovfAlloc.receiver, ovfAlloc.fields.length);
		context.prog.setComponentRecord(ovfAlloc.decl, r);
		var ic = IrClass.new(ovfAlloc.receiver, null, null, ovfAlloc.fields.extract(), []);
		newIr.setIrClass(ovfAlloc.receiver, ic);
	}
}
// An allocator for global IrFields that are used for overflow parameters and returns.
// Overflow fields must be unique within a group (i.e. for a given signature), but can
// be reused for different signatures.
class OverflowTypeEntry(var group: int, var index: int) {
	def vec = Vector<IrSpec>.new();
	def reuse(group: int) { this.group = group; index = 0; }
}
class OverflowFieldAllocator(decl: VstComponent, receiver: Type, anyref: bool) {
	def map = TypeUtil.newTypeMap<OverflowTypeEntry>();
	def fields = Vector<IrField>.new();
	var group = 0;
	def next(t: Type) -> IrSpec {
		if (anyref) {
			if (TypeSystem.isRefType(t)) t = AnyObject.TYPE;
			else if (V3.isFunction(t)) t = AnyFunction.TYPE;
		}
		var entry = map[t];
		if (entry == null) map[t] = entry = OverflowTypeEntry.new(group, 0);
		else if (entry.group < group) entry.reuse(group);
		if (entry.index == entry.vec.length) {
			var f = IrField.new(receiver, t);
			f.index = fields.length;
			fields.put(f);
			entry.vec.put(IrSpec.new(receiver, TypeUtil.NO_TYPES, f));
		}
		return entry.vec[entry.index++];
	}
}
def NONE: RaFact.set;
def live(facts: RaFact.set) -> bool {
       	return (facts & (RaFact.RC_LIVE | RaFact.RC_ALLOC)) != NONE;
}
def NO_VALUES = Array<Val>.new(0);
